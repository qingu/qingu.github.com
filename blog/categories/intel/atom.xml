<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: intel | MetMan]]></title>
  <link href="http://qingu.github.com/blog/categories/intel/atom.xml" rel="self"/>
  <link href="http://qingu.github.com/"/>
  <updated>2015-08-11T17:35:04+08:00</updated>
  <id>http://qingu.github.com/</id>
  <author>
    <name><![CDATA[Qingu Jiang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[译:为多核系统并行性能线程化Fortran应用]]></title>
    <link href="http://qingu.github.com/blog/2013/03/05/yi-wei-duo-he-xi-tong-bing-xing-xing-neng-xian-cheng-hua-fortranying-yong/"/>
    <updated>2013-03-05T20:45:00+08:00</updated>
    <id>http://qingu.github.com/blog/2013/03/05/yi-wei-duo-he-xi-tong-bing-xing-xing-neng-xian-cheng-hua-fortranying-yong</id>
    <content type="html"><![CDATA[<h3>0. 前言</h3>

<p>本文翻译自Intel网站上的一篇文章，原题为<a href="http://software.intel.com/en-us/articles/threading-fortran-applications-for-parallel-performance-on-multi-core-systems">Threading Fortran applications for parallel performance on multi-core systems</a>。由于本人翻译水平有限及专业术语知道的不多，如有不明白地方可查阅原文，发现错误的话敬请告之，谢谢！</p>

<!-- more -->

<h3>1. 正文</h3>

<p>现在大多数处理器都是多核的，预计未来性能增加主要来自于核数的增加。对于那些忽视额外核带来的机遇的性能敏感应用（performance sensitive applications）将很快被淘汰。本文讨论现存串行Fortran应用如何利用多核共享内存系统方法。议题包括数据布局，线程安全，性能及调试。Intel提供了一些软件工具帮助开发健壮、扩展性好的并行应用。</p>

<h4>并行层次</h4>

<ol>
<li><p>SIMD 指令</p>

<p>-编译器可以自动对循环向量化</p></li>
<li><p>指令级</p>

<p>-处理器调度（你看不到）</p></li>
<li><p>线程级（通常是共享内存）</p>

<p>-原生Linux或Windows线程</p>

<p>-OpenMP</p>

<p>-Simplest for muliti-core</p></li>
<li><p>分布式内存集群</p>

<p>-消息传递（一系列MPI）</p>

<p>-CoArray Fortran（未来的Fortran 2008标准）</p></li>
<li><p>embarassingly parallel multiprocessing</p></li>
</ol>

<h4>引入线程方法</h4>

<ol>
<li><p>线程库， 如 Intel® MKL</p>

<p>-容易且有效，前提是适合你的问题</p></li>
<li><p>编译器自动并行化</p>

<p>-容易做，但应用范围受限</p>

<p>-针对编译器认为安全的简单循环</p></li>
<li><p>异步I/O (非常专业，见编译器说明文档)</p></li>
<li><p>原生线程</p>

<p>-大多数用于任务级并行</p>

<p>-不是太容易编程和调试的</p></li>
<li><p>OpenMP</p>

<p>-设计用于简化数据级并行</p>

<p>-（相对的）容易编程和调试</p>

<p>-一定程度上支持任务级并行，尤其是在OpenMP 3.0中</p>

<p>-可移植性</p></li>
</ol>

<h4>Intel® Math Kernel Library</h4>

<ol>
<li><p>MKL许多部件有线程化的版本</p>

<p>-基于编译器的OpenMP运行时库</p>

<p>-1,2及3级的 BLAS , LAPACK</p>

<p>-稀疏 BLAS</p>

<p>-离散傅里叶变化</p>

<p>-向量数学和随机数函数</p>

<p>-直接稀疏求解器， 如 PARDISO</p></li>
<li><p>连接线程或非线程接口</p>

<p>-libmkl<em>intel</em>thread.a 或 libmkl_sequential.a</p>

<p>-使用link line 顾问，在 <a href="http://software.intel.com/en-us/">en-us</a></p></li>
<li><p>设置线程数</p>

<p>-设置 MKL<em>NUM</em>THREADS 或 OMP<em>NUM</em>THREADS 环境变量
-调用 mkl<em>set</em>num<em>threads 或 omp</em>set<em>num</em>threads 库函数</p></li>
</ol>

<h4>实例： PARDISO(Parallel Direct Sparse Solver)</h4>

<ol>
<li><p>共享内存系统上大型稀疏对称和非对称系统线性方程组求解器</p>

<p>-主要求解器使用OpenMP线程化</p>

<p>-仅仅连接到线程层，libmkl<em>intel</em>thread</p>

<p>-iparm(2)=3将加入线程化用于初始重排序阶段</p>

<p>-大型问题扩展性很好</p>

<p>-Fortran 90，Fortran 77 和 C 接口</p>

<p>-F90 接口能在调用序列时捕捉许多错误</p>

<p>-支持实数，复数，单双精度</p>

<p>-iterative refinement</p>

<p>-使用 MKL<em>NUM</em>THREADS 或 OMP<em>NUM</em>THREADS 环境变量控制线程变量
-否则默认处理器数（包括超线程）</p></li>
<li><p>算法见 <a href="http://www.pardiso-project.org">http://www.pardiso-project.org</a></p></li>
</ol>

<h4>自动化并行</h4>

<ol>
<li><p>编译器可对简单循环自动线程化</p>

<p>-Linux下加 -parallel 、Windows下加 /Qparallel 编译</p>

<p>-至少 -O2 等级优化（比照 OpenMP在 -O0下工作）</p>

<p>-循环必须满足“简单”条件</p>

<p>-报告哪个循环并行了，和哪个循环没有，为什么没有并行</p>

<p>-选项 -par-report2等</p>

<p>-使用选项 -par-thresholdn 微调并行代价模型</p>

<p>-默认 n=100, 尝试 n=99</p></li>
<li><p>基于和OpenMP相同的运行时库线程调用</p>

<p>-调用 <em>kmpc</em>fork_call</p>

<p>-这些是对低级pthreads 和 Win32线程库的封装</p>

<p>-识别相同的 OpenMP环境变量</p></li>
</ol>

<h4>自动化并行条件</h4>

<ol>
<li><p>入口处确定循环计数器 （DO WHILE不行）</p>

<p>-在编译时不必要确定</p>

<p>-不能跳进或跳出循环（如Fortran中循环不能有goto语句）</p></li>
<li><p>循环迭代独立</p>

<p>-没有函数调用（或证明没有负作用）</p>

<p>-除了是内联</p>

<p>-没有别名（通过不同指针访问相同变量）</p>

<p>-没有像 X(L+1)=Y(L+1) + X(L) 这样的结构</p>

<p>-允许规约</p>

<p>-但部分和可能导致舍入差异</p></li>
<li><p>工作量足以抵消并行开销</p></li>
<li><p>OpenMP循环条件类似于自动化并行条件</p></li>
<li><p>指令可用于引导编译器：</p>

<ul>
<li><p>!DIR$ PARALLEL</p></li>
<li><p>断言没有循环数据依赖</p></li>
<li><p>!DIR$ PARALLEL ALWAYS</p></li>
<li><p>重置代价模型，即使编译器认为性能不会改善（像 单个循环的-par-threshold()）也线程化循环</p></li>
<li><p>!DIR$ LOOP COUNT</p></li>
<li>估计迭代的典型数字（typical number of iterations）</li>
</ul></li>
</ol>

<h4>Example: matrix multiply</h4>

<p>```
  subroutine matmul(a,b,c,n)
  real(8) a(n,n),b(n,n),c(n,n)
  c=0.d0
  do i=1,n         ! Outer loop is parallelized.
     do j=1,n      ! inner loops are interchanged
        do k=1,n  ! new inner loop is vectorized 
           c(j,i)=c(j,i)+a(k,i)*b(j,k)
        enddo
     enddo
  enddo
  end</p>

<p>$ ifort -O3 -parallel -par-report1 -c matmul.f90
  matmul.f90(4) : (col. 0) remark: LOOP WAS AUTO-PARALLELIZED.
```</p>

<h4>OpenMP-优点</h4>

<ol>
<li><p>基于编译器指令的标准API</p>

<p>-最新版本是 3.0</p>

<p>-C++ 和 Fortran， Linux 和 Windows</p>

<p>-对不支持OpenMP编译器来说指令相当于注释</p>

<p>-串并行实现包含在一份源代码中</p>

<p>-有助于调试</p>

<p>-允许增量式并行</p>

<p>-OpenMP规则使检测工具更容易</p></li>
</ol>

<h4>OpenMP编程模型</h4>

<h5>Fork-Join 并行：</h5>

<ol>
<li><p>主线程生成一个线程组</p>

<p>-并行被增量式增加</p>

<p>-串行程序进化成并行程序</p>

<p>-线程不会被摧毁，但返回到一个线程池中（pool）</p>

<p><em>注意Intel的OpenMP实现在使用的线程之外创建了一个单独的监控线程</em></p></li>
</ol>

<h4>OpenMP-在哪线程化</h4>

<ol>
<li><p>开始于罗列高层机构</p></li>
<li><p>你的程序在哪花最多时间？</p>

<p>-如果你不知道，做下快速性能分析</p>

<p>-VTune， PTU, gprof， ...</p>

<p>-如果你的程序只有 x% 并行，加速比总是小于 x%， 无论多少核和线程。</p></li>
<li><p>更喜欢数据并行</p>

<p>-容易负载均衡</p>

<p>-容易扩展到更多核</p></li>
<li><p>喜欢粗粒度（高层次）并行</p>

<p>-例如嵌套的外层循环， 最慢变化的格点坐标， 高层驱动程序</p>

<p>-减少开销</p>

<p>-改善每个线程的数据局部性（locality）和重用性</p>

<p>-不能并行迭代循环，例如时间积分</p></li>
</ol>

<p>示例：Square_Charge</p>

<ol>
<li><p>计算一个平面上一系列点的静电势能，由于均方充电分布</p>

<p>-本质上，对一个平方的2维积分</p></li>
</ol>

<p>```
Square_charge loops over points</p>

<p>Twod_int integrate over y</p>

<p>Trap_int integrate over x</p>

<p>Func calculates 1/r potential</p>

<p>– Inline func()</p>

<p>– Vectorize loop over x</p>

<p>– Thread loop over y</p>

<pre><code>– Avoid race conditions

– Could instead thread loop over points, or use MPI ```
</code></pre>

<h4>OpenMP: 线程如何交互？</h4>

<ol>
<li><p>OpenMP 是一个共享内存模型</p>

<p>-线程之间通过共享变量通信</p></li>
<li><p>不能共享数据共享引起数据竞争：</p>

<p>-数据竞争：随线程调度不同，程序结果变化</p></li>
<li><p>控制数据竞争</p>

<p>-使用同步语句阻止数据冲突</p></li>
<li><p>同步代价昂贵，所以...</p>

<p>-改变数据访问方式尽量减少同步需求</p></li>
</ol>

<h4>OpenMP-data</h4>

<ol>
<li><p>识别哪个数据是线程间共享的，哪个是每个线程单独一个副本</p></li>
<li><p>使模块或common块中共享数据显式global，线程私有数据为局部和自动数据，这种做法有好处，但不是必须</p></li>
<li><p>动态分配 OK （malloc, ALLOCATE)</p>

<p>-如果共享，分配在串行区域</p>

<p>-如果每个线程需要各自副本，分配在并行区域</p></li>
<li><p>每个线程有它自己私有堆栈，但所以线程共享堆（heap）</p>

<p>-所以要使堆对象线程安全需要锁，而这个代价更高</p></li>
</ol>

<h4>OpenMP-数据作用域</h4>

<ol>
<li><p>区分字面显式并行区域和”动态区域“（函数或子程序在一个显式并行区域内调用。这些函数或子程序
可能不包含OpenMP指令或只包含”orphaned“ OpenMP指令</p></li>
<li><p>字面显式：!$OMP PARALLEL 到 !$OMP END PARALLEL</p>

<p>-数据默认共享（除了循环索引）</p>

<p>-局部数据：可以用 PRIVATE子句改变</p>

<p>-全局数据： 可以用 !$OMP THREADPRIVATE 申明 common块，模块变量 </p>

<p>-并行区域内初始值未定义</p>

<p>-除非用 FIRSTPRIVATE(局部变量)</p>

<p>-或 COPYIN(全局变量)</p>

<p>-出了并行区域后的值未定义</p>

<p>-除非使用 LASTPRIVATE(局部变量)</p>

<p>-调用的函数（动态区域）必须线程安全，即使他们本身不包含显式并行区域</p></li>
</ol>

<h4>线程安全</h4>

<ol>
<li><p>一个线程安全函数可以同时被多个线程调用，并仍可得出正确结果</p>

<p>-潜在的数据冲突必须被阻止（同步）或避免（私有化）</p>

<p>-静态局部数据：默认情况下，每个线程可访问相同数据地址！潜在不安全</p>

<p>-自动数据：每个线程拥有各自独立的副本，放在各自堆栈中</p></li>
<li><p>ifort 串行默认：</p>

<p>-局部标量是自动变量</p>

<p>-局部数据是静态变量</p></li>
<li><p>当用 -openmp 编译时，默认改变</p>

<p>-局部数组是自动</p>

<p>-和 -auto 编译相同</p>

<p>-这可能增加需要的堆栈大小</p>

<p>-小心段错误</p></li>
</ol>

<h4>使函数线程安全</h4>

<ol>
<li><p>使用编译选项</p>

<p>-选项 -openmp 或</p>

<p>-选项 -auto</p>

<p>-可能对串行优化有轻微影响</p></li>
<li><p>在源代码中</p>

<p>-在声明中使用 AUTOMATIC关键字</p>

<p>-但不覆盖编译器产生的临时文件</p>

<p>-声明函数为 RECURSIVE</p>

<p>-覆盖整个函数，包括编译器产生代码</p>

<p>-如果你不想依赖编译选项，这是最好办法使代码线程安全</p></li>
<li><p>下面两种情况，任意一种：</p>

<p>-不用 -save 或 SAVE 关键字</p>

<p>-避免全局变量</p>

<p>-或不要写他们，除了同步</p></li>
<li><p>OpenMP有许多同步结构保护潜在不安全的操作</p>

<ul>
<li><p>REDUCTION 子句</p></li>
<li><p>!$OMP CRITICAL</p></li>
<li><p>!$OMP SINGLE</p></li>
<li><p>等等</p></li>
</ul></li>
</ol>

<h4>线程安全库</h4>

<ol>
<li><p>Intel® MKL库是线程安全的</p>

<p>-串行版本和线程版本一样</p></li>
<li><p>Intel Fortran运行时库有两个版本</p>

<p>-默认是线程不安全的（libifcore）</p>

<p>-加 -threads 编译连接线程安全版本 （libifcoremt）</p>

<p>-如果你用 -openmp 编译， 默认连接的是线程安全版本</p></li>
</ol>

<h4>性能考虑</h4>

<ol>
<li><p>首先开始优化串行代码，向量化内循环等（例如 -O3 -ipo ...)</p></li>
<li><p>确保足够的并行工作量</p></li>
<li><p>最小化线程间数据共享</p>

<p>-除非是只读变量</p></li>
<li><p>避免cache行错误共享 （false sharing of cache lines）</p></li>
</ol>

<p><code>
    !$OMP parallel do
      do i=1,nthreads
        do j=1,1000
          A(i,j) = A(i,j) + ..
</code></p>

<p>-每个线程认为它的 A(i,j)副本可能无效</p>

<p>-转换 A 下标 改善每个线程数据 locality</p>

<p>-连续内存访问也允许内循环向量化</p>

<p>-有助于提高性能</p>

<ol>
<li><p>调度选项</p>

<p>-如果工作在循环迭代数不是均匀分布的，考虑 DYNAMIC 或 GUIDED</p></li>
</ol>

<h4>线程级应用计时</h4>

<ol>
<li><p>Fortran标准计时器 CPU_TIME 返回 ”处理器时间“</p>

<p>-所有线程/核 的时间总和</p>

<p>-很像 Linux 下 "time" 命令的 "user time"</p>

<p>-所以它可能表现为线程级应用跑的没有串行版本快</p></li>
<li><p>Fortran内置子程序 SYSTEM_CLOCK 从真实时钟返回数据</p>

<p>-不相加每个核时间</p>

<p>-很像 Linux 下 "time" 命令的 "real time"</p>

<p>-可用来测试由于线程化的加速比</p></li>
</ol>

<p><code>
   Call system_clock(count1, count_rate)
              ……
              Call system_clock(count2, count_rate)
              Time = (count2 - count1) / count_rate
</code></p>

<ol>
<li>dclock （Intel专门函数）也可以用来计时</li>
</ol>

<h4>线程亲和力（Affinity）接口</h4>

<ol>
<li><p>允许OpenMP线程绑定物理或逻辑核</p>

<p>-export 环境变量 KMP_AFFINITY=</p>

<p>-在分配逻辑核前物理上使用使用所有物理核（超线程）</p>

<p>-紧密分配线程给相同socket连续核（例如受益于共享cache）</p>

<p>-分散分配线程给交替sockets（例如使内存通道最大化）</p>

<p>-有助于优化内存或cache访问</p>

<p>-如果超线程支持的话，尤其重要</p>

<p>-否则一些物理核闲置而另外一些跑多个线程</p>

<p>-详情见编译器文档</p></li>
</ol>

<h4>NUMA考虑</h4>

<ol>
<li><p>想要内存分配更接近它将要使用的地方</p>

<ul>
<li>"first touch" 决定分配位置</li>
</ul>

<p>-所以初始化一个OpenMP循环内数据方式与你计划之后要用到的方式一样</p></li>
</ol>

<p><code>
  !$OMP parallel do                      !$OMP parallel do
        do i=1,n                                   do i=1,n
          do j=1,m                                  do j=1,m
            A(j,i) = 0.0                               dowork(A(j,i)) 
          enddo                                      enddo
        enddo                                      enddo
</code></p>

<ol>
<li>记住设置 KMP_AFFINITY</li>
</ol>

<h4>常见问题</h4>

<ol>
<li><p>不足的堆栈大小</p>

<p>-OpenMP中最经常遇到的问题</p>

<p>-典型症状： 初始化是段错误</p></li>
<li><p>对于整个程序（共享+局部数据）：</p>

<p>-增加shell limits值</p>

<p>-（地址空间，内存分配）</p>

<ul>
<li>Bash : <code>ulimit -s [value in KB] or [unlimited]</code></li>
</ul>

<p>-只增加一次</p>

<ul>
<li><p>C shell： <code>limit stacksize 1000000</code> (1 GB)</p></li>
<li><p>Windows : /F:100000000 (以字节为单位)</p></li>
<li><p>典型 OS 默认： ~ 10 MB</p></li>
</ul></li>
<li><p>对于单个线程（只针对线程局部数据）</p>

<ul>
<li>export OMP_STACKSIZE=[size]，默认4 MB</li>
</ul>

<p>-实际分配内存，不要设置太大</p></li>
</ol>

<h4>调试 OpenMP 应用提示</h4>

<ol>
<li><p>设置 OMP<em>NUM</em>THREADS=1 运行</p>

<p>-产生线程级代码，但用一个线程运行</p>

<p>-如果工作，产生对线程代码Thread Checker</p>

<p>-如果失败，排除数据竞争或其他同步问题原因</p></li>
<li><p>用 -openmp-stubs-auto 编译</p>

<p>-RTL调用被解决，但没有线程级代码产生</p>

<p>-分配局部数组在堆栈上，和OpenMP一样</p>

<p>-如果工作，检查缺失的 FIRSTPRIVATE ，LASTPRIVATE</p>

<p>-如果失败， 消除了线程级代码产生原因</p></li>
<li><p>如果没有 -auto 编译，隐含改变内存模型</p>

<p>-可能不足的堆栈大小</p>

<p>-可能连续调用之间值未保存</p></li>
<li><p>如果用 PRINT 语句调试</p>

<p>-内部I/O缓冲线程安全（加上-openmp),但不同线程打印语句顺序不确定</p>

<p>-输出线程号用 omp<em>get</em>thread_num()</p>

<p>-记住调用模块 USE OMP_LIB (申明这个是整数)</p></li>
<li><p>用 -O0 -openmp 调试</p>

<p>-不行其它优化，OpenMP线程在 -O0 等级时不关闭</p></li>
</ol>

<h4>浮点重复性</h4>

<ol>
<li><p>用不同数量线程运行同样程序可能得出稍微不同结果</p>

<p>-由于不同工作分解导致微小的舍入差异</p>

<p>-大多数情况可通过 -fp-model precise 解决</p>

<p>-查看  “<a href="http://software.intel.com/en-us/articles/consistency-of-floating-point-results-using-the-intel-compiler">Consistency of Floating-Point Results using the Intel® Compiler</a>”</p></li>
<li><p>在OpenMP中浮点规约仍不能严格再现，即使线程数相同</p>

<p>-不同线程贡献顺序每次运行可能都不同</p>

<ul>
<li>-fp-model precise 这儿没什么帮助</li>
</ul>

<p>-如果关心这个，需要些显式代码</p></li>
</ol>

<h4>Intel 专门环境变量</h4>

<ol>
<li><p>KMP_SETTINGS = 0 | 1</p>

<p>-在运行时打印环境变量或默认</p></li>
<li><p>KMP_VERSION = off | on</p>

<p>-打印运行时库版本</p></li>
<li><p>KMP_LIBRARY = turnaround | throughput | serial</p>

<ul>
<li><p>turnaround idle threads do not yield to other processes</p></li>
<li><p>throughput idle threads sleep and yield after KMP_BLOCKTIME msec</p></li>
</ul></li>
<li><p>KMP_BLOCKTIME</p>

<ul>
<li>线程在睡眠前等待时间（默认200毫秒）</li>
</ul></li>
<li><p>KMP_AFFINITY </p></li>
<li><p>KMP<em>MONITOR</em>STACKSIZE</p>

<p>-设置分配给监控线程的堆栈</p></li>
<li><p>KMP<em>CPUINFO</em>FILE</p>

<p>-使用机器拓扑文件（例如代替Linux的 /proc/cpuinfo）</p></li>
</ol>

<h4>调试 OpenMP 应用工具</h4>

<ol>
<li><p>编译器源代码checker （'parallel lint')</p>

<ul>
<li><p>ifort -openmp -diag-enable sc-parallel3</p></li>
<li><p>产生一些可能API违规操作的错误和警告诊断，包括</p></li>
</ul>

<p>-依赖性或数据竞争</p>

<p>-例如：由于缺少 PRIVATE 或 REDUCTION 申明</p>

<p>-并行区域闭一只，包括动态区域</p>

<p>-可以跨源文件分析</p></li>
<li><p>Updated Intel Parallel Debugger, idb (Linux) and Intel Parallel Debugger Extension (on Windows)</p>

<p>– Thread groups; lock-stepping; thread-specific break points</p>

<p>– On-the-fly serialization; shared data access detection</p>

<p>– OpenMP windows for threads, tasks, barriers, locks, …</p>

<p>– New for Fortran in version 11.1 update 2</p></li>
</ol>

<h4>Intel® Thread Checker</h4>

<ol>
<li><p>Unified set of tools that pinpoint hard-to-find errors in multi-threaded applications
– data races</p>

<p>– deadlocks</p>

<p>– memory defects</p>

<p>– security issues</p></li>
<li><p>Display data at the Linux command line or via a Windows GUI</p></li>
</ol>

<h4>Intel® Thread Profiler</h4>

<ol>
<li><p>Features &amp; Benefits</p>

<p>– View application concurrency level to ensure core utilization</p>

<p>– Identify where thread and synchronization related overhead impacts performance</p>

<p>– Identify objects impacting performance</p>

<p>– Visualize the distribution of work to threads</p>

<p>– Visualize when threads are active and inactive</p>

<p>– Supports native threads , Intel® Threading Building Blocks or OpenMP* applications on Windows* for IA-32/Intel® 64 architecture</p>

<p>– Data collector for Linux, but must copy to Windows for display.</p></li>
</ol>

<h4>总结</h4>

<p>Intel软件工具提供对利用多核架构线程级应用扩展支持。</p>

<p>提供线程化一个Fortran应用时引起的一系列问题的建议和背景信息。</p>

<h4>引用</h4>

<p>[1]  <a href="http://www.intel.com/software/products">Intel Software Products information, evaluations, active user forums</a></p>

<p>[2]  <a href="http://www.devx.com/go-parallel"> Parallelism tips</a></p>

<p>[3]  <a href="http://software.intel.com/en-us/articles/developing-multithreaded-applications-a-platform-consistent-approach"> Developing Multithreaded Applications: A Platform Consistent Approach</a></p>

<p>[4]  <a href="http://software.intel.com/en-us/"> The Intel® Fortran Compiler User and Reference Guides, available online</a></p>
]]></content>
  </entry>
  
</feed>
